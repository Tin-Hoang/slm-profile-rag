# RAG Chatbot Configuration

# Profile Information
profile:
  name: "Tin Hoang"  # Change to your name
  title: "AI Research Engineer | MLOps Engineer"
  greeting: "Hi! I'm a chatbot trained on {name}'s professional background. Ask me anything about their experience, skills, and projects!"

# LLM Configuration
llm:
  provider: "ollama"  # Options: ollama, openai, anthropic, groq
  model: "llama3.2:3b"  # For Ollama. Other options: phi3:mini, gemma2:2b
  temperature: 0.7
  max_tokens: 512
  top_p: 0.9

  # System prompt template
  system_prompt: |
    You are a knowledgeable AI assistant that helps answer questions about {name}, a {title}.
    You have been trained on their resume, project reports, LinkedIn profile, and professional documents.

    Your role is to provide accurate information about {name}'s:
    - Professional experience and work history
    - Technical skills and expertise
    - Projects and accomplishments
    - Education and certifications
    - Professional background and interests

    Communication Guidelines:
    - Be professional, helpful, and balanced in tone
    - Speak in third person about {name} (e.g., "Tin has experience in...", "His focus is on...")
    - Present information factually without over-selling
    - Stay grounded in the available context
    - Be honest about the limits of your knowledge

    When Information is Limited:
    - Be direct but not negative: "Based on the available profile, Tin has..."
    - Focus on what IS documented rather than what ISN'T
    - Suggest connecting directly for details: "For more specific details, it would be best to connect with Tin directly"
    - Avoid repeatedly saying "I don't have information" - instead briefly acknowledge and move forward
    - Keep responses concise and to the point

    Important Reminders:
    - You are an AI assistant, not Tin himself - maintain this distinction
    - Only share information from the provided context - no fabrication
    - If uncertain, acknowledge it briefly: "The available information suggests..." or "Based on the profile..."
    - Keep responses realistic and professional (2-3 paragraphs max)
    - Avoid over-enthusiastic or salesy language

# Embedding Model Configuration
embeddings:
  model_name: "sentence-transformers/all-MiniLM-L6-v2"
  # Alternative: "sentence-transformers/all-mpnet-base-v2" (better quality, slower)
  device: "cpu"  # Options: cpu, cuda, mps

# Vector Database Configuration
vectorstore:
  type: "chroma"
  collection_name: "profile_documents"
  persist_directory: "./chroma_db"

  # Search configuration
  search_type: "similarity"  # Options: similarity, mmr
  search_kwargs:
    k: 4  # Number of documents to retrieve
    fetch_k: 20  # For MMR
    lambda_mult: 0.5  # For MMR diversity

# Document Processing Configuration
document_processing:
  # Chunking strategy
  chunk_size: 1000  # Characters per chunk
  chunk_overlap: 200  # Overlap between chunks

  # Supported file types
  supported_extensions:
    - .pdf
    - .docx
    - .doc
    - .html
    - .htm
    - .txt
    - .md

  # PDF processing
  pdf:
    extract_images: false

  # HTML processing
  html:
    parse_tables: true
    strip_tags: true

# Main Document Configuration
main_document:
  enabled: true  # Master switch for the feature
  path: "data/documents/main_profile.md"  # Path to main document
  max_tokens: 10000  # Maximum tokens allowed (generous limit)
  position: "before"  # Always before VectorDB context (high priority)

  # Auto-detect format from file extension
  # Supported: .md, .txt, .pdf, .docx, .html

  # Summarization settings
  summarize_if_exceeds: true  # Use LLM to summarize if > max_tokens
  summarization_target_tokens: 8000  # Target size after summarization
  summarization_prompt: |
    You are summarizing a professional profile document.
    Extract and preserve ALL critical information including:
    - Full name, title, and contact information
    - Current role and key responsibilities
    - Core technical skills and expertise areas
    - Major projects and accomplishments with metrics
    - Education and certifications
    - Professional background summary

    Maintain factual accuracy. Keep all numbers, dates, and specific achievements.
    Output a concise but comprehensive summary that captures the person's professional identity.

  # Caching
  cache_enabled: true  # Cache loaded content (reload only on file change)
  cache_check_interval: 60  # Check file modification time every N seconds

  # Error handling
  fail_silently: true  # Continue without main doc if loading fails
  fallback_to_vectordb_only: true  # Use only VectorDB if main doc unavailable

# RAG Pipeline Configuration
rag:
  # Retrieval settings
  retrieval_mode: "contextual"  # Options: simple, contextual, hybrid

  # Reranking (optional, set to false if not using)
  use_reranking: false

  # Context window
  max_context_length: 3000  # Characters of context to include

  # Response settings
  include_sources: true  # Show source documents in response
  source_max_length: 150  # Max length of source preview
  enhance_responses: true  # Apply post-processing to improve tone and remove negative language

# UI Configuration
ui:
  page_title: "ðŸ’¬ Profile Q&A Chatbot"
  page_icon: "ðŸ¤–"
  layout: "centered"  # Options: centered, wide

  # Styling
  theme:
    primary_color: "#FF4B4B"
    background_color: "#FFFFFF"
    secondary_background_color: "#F0F2F6"
    text_color: "#262730"

  # Chat settings
  max_chat_history: 50
  show_timestamps: true

  # Example questions
  example_questions:
    - "What is {name}'s background?"
    - "What are {name}'s key technical skills?"
    - "Tell me about {name}'s recent projects"
    - "What is {name}'s educational background?"
    - "What kind of roles is {name} looking for?"

# Logging Configuration
logging:
  level: "INFO"  # Options: DEBUG, INFO, WARNING, ERROR
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "app.log"
  max_bytes: 10485760  # 10MB
  backup_count: 3
